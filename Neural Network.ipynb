{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373198</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.062858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.163383</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.096995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.439809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005278</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived      Pclass   Sex         Age       SibSp       Parch  \\\n",
       "count   891.000000  891.000000   891  891.000000  891.000000  891.000000   \n",
       "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
       "top            NaN         NaN  male         NaN         NaN         NaN   \n",
       "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
       "mean      0.383838    2.308642   NaN    0.373198    0.523008    0.381594   \n",
       "std       0.486592    0.836071   NaN    0.163383    1.102743    0.806057   \n",
       "min       0.000000    1.000000   NaN    0.005278    0.000000    0.000000   \n",
       "25%       0.000000    2.000000   NaN    0.276451    0.000000    0.000000   \n",
       "50%       0.000000    3.000000   NaN    0.373198    0.000000    0.000000   \n",
       "75%       1.000000    3.000000   NaN    0.439809    1.000000    0.000000   \n",
       "max       1.000000    3.000000   NaN    1.005278    8.000000    6.000000   \n",
       "\n",
       "              Fare  \n",
       "count   891.000000  \n",
       "unique         NaN  \n",
       "top            NaN  \n",
       "freq           NaN  \n",
       "mean      0.062858  \n",
       "std       0.096995  \n",
       "min       0.000000  \n",
       "25%       0.015440  \n",
       "50%       0.028213  \n",
       "75%       0.060508  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.drop(['PassengerId', 'Name', 'Ticket', 'Embarked'], axis=1, inplace=True)\n",
    "train.describe(include='all')\n",
    "train.fillna(value={'Age': train['Age'].mean()}, inplace=True)\n",
    "train.dropna(axis=1, inplace=True)\n",
    "train['Age'] = train['Age'] / (train['Age'].max() - train['Age'].min())\n",
    "train['Fare'] = train['Fare'] / (train['Fare'].max() - train['Fare'].min())\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((9, train.shape[0]))\n",
    "Y_train = np.zeros((train.shape[0], 1))\n",
    "\n",
    "for i, x in train.iterrows():\n",
    "    X_train[x['Pclass'] - 1, i] = 1\n",
    "    if x['Sex'] == 'M':\n",
    "        X_train[3, i] = 1\n",
    "    else:\n",
    "        X_train[4, i] = 1\n",
    "    X_train[5:, i] = x['Age'], x['SibSp'], x['Parch'], x['Fare']\n",
    "    Y_train[i] = x['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layers_dims):\n",
    "    L = len(layers_dims)\n",
    "    parameters = {}\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    L = len(parameters) // 2\n",
    "    A_prev = X\n",
    "    caches = []\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        \n",
    "        Z = np.dot(W, A_prev) + b\n",
    "        caches.append((A_prev, W, b, Z))\n",
    "        A_prev = relu(Z)\n",
    "    \n",
    "    W = parameters['W' + str(L)]\n",
    "    b = parameters['b' + str(L)]\n",
    "    \n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    caches.append((A_prev, W, b, Z))\n",
    "    AL = sigmoid(Z)\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    return (1 / m) * (np.dot(np.log(AL), Y) + np.dot(np.log(1 - AL), 1 - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dsigmoid(z):\n",
    "    g = sigmoid(z)\n",
    "    return g * (1 - g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drelu(z):\n",
    "    return (z > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagation(AL, Y, caches):\n",
    "    grads = {}\n",
    "    m = Y.shape[0]\n",
    "    L = len(caches)\n",
    "    dAL = np.divide(1 - Y.T, 1 - AL) - np.divide(Y.T, AL)\n",
    "    A_prev, W, b, Z = caches[L - 1]\n",
    "    \n",
    "    dZ = dAL * dsigmoid(Z)\n",
    "    grads['dW' + str(L)] = (1 / m) * np.dot(dZ, A_prev.T)\n",
    "    grads['db' + str(L)] = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    for l in reversed(range(1, L)):\n",
    "        A_prev, W, b, Z = caches[l - 1]\n",
    "        dZ = dA_prev * drelu(Z)\n",
    "        grads['dW' + str(l)] = (1 / m) * np.dot(dZ, A_prev.T)\n",
    "        grads['db' + str(l)] = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "        dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] -= learning_rate * grads['dW' + str(l)]\n",
    "        parameters['b' + str(l)] -= learning_rate * grads['db' + str(l)]\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network(X, Y, layers_dims, learning_rate=0.01, num_iterations=2500, print_costs=False):\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        AL, caches = forward_propagation(X, parameters)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = backward_propagation(AL, Y, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        costs.append(cost)\n",
    "        if print_costs and i % 1000 == 0:\n",
    "            print('Cost after ', i, ' iteration:', cost)\n",
    "    \n",
    "    Y_pred = (AL > 0.5) * 1\n",
    "    print('Training accuracy:', (100 / Y.shape[0]) * (np.dot(Y_pred, Y) + np.dot(1 - Y_pred, 1 - Y)))\n",
    "    \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Iterations')\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after  0  iteration: [[ 0.69314427]]\n",
      "Cost after  500  iteration: [[ 0.6080888]]\n",
      "Cost after  1000  iteration: [[ 0.6036739]]\n",
      "Cost after  1500  iteration: [[ 0.58390413]]\n",
      "Cost after  2000  iteration: [[ 0.56167534]]\n",
      "Cost after  2500  iteration: [[ 0.55820314]]\n",
      "Cost after  3000  iteration: [[ 0.55653219]]\n",
      "Cost after  3500  iteration: [[ 0.55470719]]\n",
      "Cost after  4000  iteration: [[ 0.55334562]]\n",
      "Cost after  4500  iteration: [[ 0.55235276]]\n",
      "Cost after  5000  iteration: [[ 0.55147565]]\n",
      "Cost after  5500  iteration: [[ 0.55045717]]\n",
      "Cost after  6000  iteration: [[ 0.54954206]]\n",
      "Cost after  6500  iteration: [[ 0.54867342]]\n",
      "Cost after  7000  iteration: [[ 0.54798386]]\n",
      "Cost after  7500  iteration: [[ 0.54717743]]\n",
      "Cost after  8000  iteration: [[ 0.54651805]]\n",
      "Cost after  8500  iteration: [[ 0.54606068]]\n",
      "Cost after  9000  iteration: [[ 0.54533486]]\n",
      "Cost after  9500  iteration: [[ 0.54492271]]\n",
      "Cost after  10000  iteration: [[ 0.54453248]]\n",
      "Cost after  10500  iteration: [[ 0.54395982]]\n",
      "Cost after  11000  iteration: [[ 0.54353805]]\n",
      "Cost after  11500  iteration: [[ 0.54326149]]\n",
      "Cost after  12000  iteration: [[ 0.54304806]]\n",
      "Cost after  12500  iteration: [[ 0.54285495]]\n",
      "Cost after  13000  iteration: [[ 0.54266609]]\n",
      "Cost after  13500  iteration: [[ 0.54248878]]\n",
      "Cost after  14000  iteration: [[ 0.54233396]]\n",
      "Cost after  14500  iteration: [[ 0.54217471]]\n",
      "Cost after  15000  iteration: [[ 0.54202842]]\n",
      "Cost after  15500  iteration: [[ 0.54174478]]\n",
      "Cost after  16000  iteration: [[ 0.54150706]]\n",
      "Cost after  16500  iteration: [[ 0.54126243]]\n",
      "Cost after  17000  iteration: [[ 0.54108307]]\n",
      "Cost after  17500  iteration: [[ 0.54092579]]\n",
      "Cost after  18000  iteration: [[ 0.54075342]]\n",
      "Cost after  18500  iteration: [[ 0.54059384]]\n",
      "Cost after  19000  iteration: [[ 0.54043521]]\n",
      "Cost after  19500  iteration: [[ 0.54027286]]\n",
      "Training accuracy: [[ 73.28843996]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNNKHQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ecda277eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers_dims = [9, 50, 10, 1]\n",
    "model = neural_network(X_train, Y_train, layers_dims, 5, 20000, print_costs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.318094</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>0.069374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.230711</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.109046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.316497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002242</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId      Pclass   Sex         Age       SibSp       Parch  \\\n",
       "count    418.000000  418.000000   418  418.000000  418.000000  418.000000   \n",
       "unique          NaN         NaN     2         NaN         NaN         NaN   \n",
       "top             NaN         NaN  male         NaN         NaN         NaN   \n",
       "freq            NaN         NaN   266         NaN         NaN         NaN   \n",
       "mean    1100.500000    2.265550   NaN    0.318094    0.447368    0.392344   \n",
       "std      120.810458    0.841838   NaN    0.230711    0.896760    0.981429   \n",
       "min      892.000000    1.000000   NaN    0.002242    0.000000    0.000000   \n",
       "25%      996.250000    1.000000   NaN    0.118687    0.000000    0.000000   \n",
       "50%     1100.500000    3.000000   NaN    0.316497    0.000000    0.000000   \n",
       "75%     1204.750000    3.000000   NaN    0.471449    1.000000    0.000000   \n",
       "max     1309.000000    3.000000   NaN    1.002242    8.000000    9.000000   \n",
       "\n",
       "              Fare  \n",
       "count   418.000000  \n",
       "unique         NaN  \n",
       "top            NaN  \n",
       "freq           NaN  \n",
       "mean      0.069374  \n",
       "std       0.109046  \n",
       "min       0.000000  \n",
       "25%       0.015412  \n",
       "50%       0.028213  \n",
       "75%       0.061429  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.drop(['Name', 'Ticket', 'Embarked'], axis=1, inplace=True)\n",
    "test.fillna(value={'Age': train['Age'].mean()}, inplace=True)\n",
    "test.fillna(value={'Fare': train['Fare'].mean()}, inplace=True)\n",
    "test.dropna(axis=1, inplace=True)\n",
    "test['Age'] = test['Age'] / (test['Age'].max() - test['Age'].min())\n",
    "test['Fare'] = test['Fare'] / (test['Fare'].max() - test['Fare'].min())\n",
    "test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((9, test.shape[0]))\n",
    "\n",
    "for i, x in test.iterrows():\n",
    "    X[x['Pclass'] - 1, i] = 1\n",
    "    if x['Sex'] == 'M':\n",
    "        X[3, i] = 1\n",
    "    else:\n",
    "        X[4, i] = 1\n",
    "    X[5:, i] = x['Age'], x['SibSp'], x['Parch'], x['Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    L = len(parameters) // 2\n",
    "    A_prev = X\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        Z = np.dot(parameters['W' + str(l)], A_prev) + parameters['b' + str(l)]\n",
    "        A_prev = relu(Z)\n",
    "    \n",
    "    Z = np.dot(parameters['W' + str(L)], A_prev) + parameters['b' + str(L)]\n",
    "    return (sigmoid(Z) > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_pred = predict(X, model).T\n",
    "print(Y_pred.shape)\n",
    "test['Survived'] = Y_pred\n",
    "test[['PassengerId', 'Survived']].astype(int).to_csv('submission_neural_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
